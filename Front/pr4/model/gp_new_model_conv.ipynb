{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPx8nZ5wfTDK3QDvHiORYkP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/201921027/graduate_project_git/blob/main/gp_new_model_conv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOCarEVUJqw8",
        "outputId": "8db0acc4-fcfe-4395-a0d7-e98f9d4dc953"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/MyDrive/Colab Notebooks/graduation_project'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LkxpM2iNvVO",
        "outputId": "39cb1beb-29b0-4f56-e58e-20286f7631af"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/graduation_project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "## CPU\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "## GPU\n",
        "# device = torch.device(\"cuda\")"
      ],
      "metadata": {
        "id": "CbjVmJARPdvH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gluonnlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQ7PJ2ZxQV-N",
        "outputId": "8421f0ec-7f59-4222-9364-87171872b6b8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gluonnlp\n",
            "  Downloading gluonnlp-0.10.0.tar.gz (344 kB)\n",
            "\u001b[K     |████████████████████████████████| 344 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (1.21.6)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (0.29.32)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp) (3.0.9)\n",
            "Building wheels for collected packages: gluonnlp\n",
            "  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp37-cp37m-linux_x86_64.whl size=595749 sha256=c44df2e020e06c31831bd2d84a394a2ca7f439ec0293004eaf2a59460a55c568\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/b4/06/7f3fdfaf707e6b5e98b79c041e023acffbe395d78a527eae00\n",
            "Successfully built gluonnlp\n",
            "Installing collected packages: gluonnlp\n",
            "Successfully installed gluonnlp-0.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mxnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mewCrxuMQh-b",
        "outputId": "f82e9886-1d7f-427a-f31e-da658eb3ca6b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mxnet\n",
            "  Downloading mxnet-1.9.1-py3-none-manylinux2014_x86_64.whl (49.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 49.1 MB 2.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.21.6)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n",
            "Collecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
            "Installing collected packages: graphviz, mxnet\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-1.9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "I3MP5S_9SZjz",
        "outputId": "d1d9a960-e7c8-406e-a8ca-a2a09cf2c948"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n",
            "  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-v1qnjw3p\n",
            "  Running command git clone -q 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-v1qnjw3p\n",
            "Collecting boto3<=1.15.18\n",
            "  Downloading boto3-1.15.18-py2.py3-none-any.whl (129 kB)\n",
            "\u001b[K     |████████████████████████████████| 129 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gluonnlp<=0.10.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (0.10.0)\n",
            "Collecting mxnet<=1.7.0.post2,>=1.4.0\n",
            "  Downloading mxnet-1.7.0.post2-py2.py3-none-manylinux2014_x86_64.whl (54.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 54.7 MB 9.5 MB/s \n",
            "\u001b[?25hCollecting onnxruntime<=1.8.0,==1.8.0\n",
            "  Downloading onnxruntime-1.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.5 MB 10.0 MB/s \n",
            "\u001b[?25hCollecting sentencepiece<=0.1.96,>=0.1.6\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 44.8 MB/s \n",
            "\u001b[?25hCollecting torch<=1.10.1,>=1.7.0\n",
            "  Downloading torch-1.10.1-cp37-cp37m-manylinux1_x86_64.whl (881.9 MB)\n",
            "\u001b[K     |██████████████████████████████▎ | 834.1 MB 1.1 MB/s eta 0:00:42tcmalloc: large alloc 1147494400 bytes == 0x39f5e000 @  0x7f7ca8be7615 0x58e046 0x4f2e5e 0x4d19df 0x51b31c 0x5b41c5 0x58f49e 0x51b221 0x5b41c5 0x58f49e 0x51837f 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4ba70a 0x538136 0x590055 0x51b180 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51740e 0x58f2a7 0x517947 0x5b41c5 0x58f49e\n",
            "\u001b[K     |████████████████████████████████| 881.9 MB 14 kB/s \n",
            "\u001b[?25hCollecting transformers<=4.8.1,>=4.8.1\n",
            "  Downloading transformers-4.8.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 43.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (3.17.3)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (1.21.6)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (2.0.7)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "  Downloading s3transfer-0.3.7-py2.py3-none-any.whl (73 kB)\n",
            "\u001b[K     |████████████████████████████████| 73 kB 2.0 MB/s \n",
            "\u001b[?25hCollecting botocore<1.19.0,>=1.18.18\n",
            "  Downloading botocore-1.18.18-py2.py3-none-any.whl (6.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7 MB 55.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.26,>=1.20 in /usr/local/lib/python3.7/dist-packages (from botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (1.24.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (21.3)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (0.29.32)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2.23.0)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (0.8.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2022.6.15)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<=1.10.1,>=1.7.0->kobert==0.2.3) (4.1.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 28.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (3.8.0)\n",
            "Collecting huggingface-hub==0.0.12\n",
            "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (6.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 42.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (4.64.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (4.12.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (2022.6.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (1.1.0)\n",
            "Building wheels for collected packages: kobert, sacremoses\n",
            "  Building wheel for kobert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kobert: filename=kobert-0.2.3-py3-none-any.whl size=15708 sha256=cda27dcd6db5893ac30efb924104f5ecd91185928cc106596affd1dcad03ec49\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zv6eofee/wheels/d3/68/ca/334747dfb038313b49cf71f84832a33372f3470d9ddfd051c0\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=5ccec7b19f83825cb1fae19bea0a0a3b1febc5cb7f20fd1ccbaef78ed93e826e\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built kobert sacremoses\n",
            "Installing collected packages: jmespath, botocore, tokenizers, sacremoses, s3transfer, huggingface-hub, transformers, torch, sentencepiece, onnxruntime, mxnet, boto3, kobert\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "  Attempting uninstall: mxnet\n",
            "    Found existing installation: mxnet 1.9.1\n",
            "    Uninstalling mxnet-1.9.1:\n",
            "      Successfully uninstalled mxnet-1.9.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.10.1 which is incompatible.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.10.1 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.10.1 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.15.18 botocore-1.18.18 huggingface-hub-0.0.12 jmespath-0.10.0 kobert-0.2.3 mxnet-1.7.0.post2 onnxruntime-1.8.0 s3transfer-0.3.7 sacremoses-0.0.53 sentencepiece-0.1.96 tokenizers-0.10.3 torch-1.10.1 transformers-4.8.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 사용자 input\n",
        "\n",
        "# 서버에서 본문 받아오기\n",
        "# 서버에서 아마 csv나 json으로 받아올텐데, 받아올 때 특수문자 처리 필수 (특히 따옴표 '', \"\")\n",
        "# '[제목] 본문' 형태로 전처리\n",
        "# //////////////////////서버로부터 본문 받아와서 str로 저장하는 line////////////////////////\n",
        "input_text= \"[평범한 일상] 오늘은 아주 무난한 하루를 보냈다. 팝송도 듣고, 산책도 하고 등등. 매일이 오늘 같았으면 좋겠다!\"\n",
        "\n",
        "if len(input_text) + len(\" TL;DR \") > 800:\n",
        "  input_text = input_text[0:400] + input_text[len(input_text)-400:len(input_text)]"
      ],
      "metadata": {
        "id": "1VHcyE1YMgjv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* BERT"
      ],
      "metadata": {
        "id": "HPucZsPENgkO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from kobert import get_pytorch_kobert_model\n",
        "\n",
        "bertmodel, vocab  = get_pytorch_kobert_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPpGPRM1RfS8",
        "outputId": "fd2f5d0f-09af-4648-a4c2-2dcfe5dd1b19"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cached model. /content/drive/MyDrive/Colab Notebooks/graduation_project/.cache/kobert_v1.zip\n",
            "using cached model. /content/drive/MyDrive/Colab Notebooks/graduation_project/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gluonnlp as nlp\n",
        "from kobert import get_tokenizer\n",
        "\n",
        "bert_tokenizer = get_tokenizer()\n",
        "tok = nlp.data.BERTSPTokenizer(bert_tokenizer, vocab, lower=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-FRbbeUTrt-",
        "outputId": "1ccf20d6-8700-477d-8a9e-7312ab1efb01"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cached model. /content/drive/MyDrive/Colab Notebooks/graduation_project/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_size = 768,\n",
        "                 num_classes=5,\n",
        "                 dr_rate=None,\n",
        "                 params=None):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dr_rate = dr_rate\n",
        "                 \n",
        "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
        "        if dr_rate:\n",
        "            self.dropout = nn.Dropout(p=dr_rate)\n",
        "    \n",
        "    def gen_attention_mask(self, token_ids, valid_length):\n",
        "        attention_mask = torch.zeros_like(token_ids)\n",
        "        for i, v in enumerate(valid_length):\n",
        "            attention_mask[i][:v] = 1\n",
        "        return attention_mask.float()\n",
        "\n",
        "    def forward(self, token_ids, valid_length, segment_ids):\n",
        "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "        \n",
        "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
        "        if self.dr_rate:\n",
        "            out = self.dropout(pooler)\n",
        "        else:\n",
        "            out = pooler\n",
        "        return self.classifier(out)"
      ],
      "metadata": {
        "id": "62pl4s2NU2RI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)"
      ],
      "metadata": {
        "id": "7dwz_NOcU3JG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model load\n",
        "bert_model.load_state_dict(torch.load('./checkpoint/bert_model.pt', map_location=device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwKTN9fWMtaA",
        "outputId": "28d0aa38-54c3-4fd3-b9a3-6f146be89b67"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 512"
      ],
      "metadata": {
        "id": "ce-8oXNVQIkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 기쁨:0 분노:1 혐오:2 두려움:3 슬픔:4 unknown:5\n",
        "\n",
        "def softmax(vals, idx):\n",
        "    valscpu = vals.cpu().detach().squeeze(0)\n",
        "    a = 0\n",
        "    for i in valscpu:\n",
        "        a += np.exp(i)\n",
        "    return ((np.exp(valscpu[idx]))/a).item() * 100\n",
        "\n",
        "def testModel(model, seq):\n",
        "    cate = [\"기쁨\", \"분노\", \"혐오\", \"두려움\", \"슬픔\", \"unknown\"]\n",
        "    tmp = [seq]\n",
        "    transform = nlp.data.BERTSentenceTransform(tok, max_len, pad=True, pair=False)\n",
        "    tokenized = transform(tmp)\n",
        "\n",
        "    model.eval()\n",
        "    result = model(torch.tensor([tokenized[0]]).to(device), [tokenized[1]], torch.tensor(tokenized[2]).to(device))\n",
        "    idx = result.argmax().cpu().item()\n",
        "    print(\"일기의 감정:\", cate[idx])\n",
        "    print(\"신뢰도:\", \"{:.2f}%\".format(softmax(result,idx)))\n",
        "    return cate[idx]"
      ],
      "metadata": {
        "id": "S_HkTCNbNqOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion= testModel(bert_model, input_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IueYeUeOWAFV",
        "outputId": "59ff93fe-e93c-4a0b-ddb0-106ea4d78f35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "일기의 감정: 슬픔\n",
            "신뢰도: 19.42%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* KoGPT"
      ],
      "metadata": {
        "id": "E-n-dezxWZCv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel\n",
        "\n",
        "gpt_model= GPT2LMHeadModel.from_pretrained('./checkpoint/gpt_model_1.pt')"
      ],
      "metadata": {
        "id": "SRvHV7-KXhN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import PreTrainedTokenizerFast\n",
        "\n",
        "gpt_tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n",
        "  bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n",
        "  pad_token='<pad>', mask_token='<mask>')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-8u29FiYFMS",
        "outputId": "bca16027-355e-407b-c367-131d8a9b2404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
            "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# input_text= \"[평범한 일상] 오늘은 아주 무난한 하루를 보냈다. 팝송도 듣고, 산책도 하고 등등. 매일이 오늘 같았으면 좋겠다!\"\n",
        "input_text= input_text + \" TL;DR \"\n",
        "text= emotion + '| ' + input_text\n",
        "# print(text)"
      ],
      "metadata": {
        "id": "PWvB097YWCIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = gpt_tokenizer.encode(text, return_tensors='pt')\n",
        "gen_ids = gpt_model.generate(input_ids,\n",
        "                           max_length=len(input_ids[0])+ 50, # 50 -> 약 120자\n",
        "                           repetition_penalty=2.0,\n",
        "                           pad_token_id=gpt_tokenizer.pad_token_id,\n",
        "                           eos_token_id=gpt_tokenizer.eos_token_id,\n",
        "                           bos_token_id=gpt_tokenizer.bos_token_id,\n",
        "                           use_cache=True).to(device)\n",
        "generated = gpt_tokenizer.decode(gen_ids[0])\n",
        "# print(generated)"
      ],
      "metadata": {
        "id": "aKDaT9TMWNNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TLDR_index= generated.index('TL;DR')\n",
        "output= generated[TLDR_index+6:]\n",
        "print('return comment:' , output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2uT3I6OX4kA",
        "outputId": "4c491967-6a4e-431e-b669-2ff577db07d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "return comment:  그날의 일이 있었다. 나는 언제나 좋은 일을 했다. 그리고 내가 너무 힘들었다. 하지만 그렇게 생각해요. 그래도 그랬으니까 모른지도 못 쓰는 것은 물론 매일 아침이 되었다. 그러나 이제 엄마냥 한 편하기 바랄 수 없는 것 같아요 당화가 되어\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gQLRh7uUYcPK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}