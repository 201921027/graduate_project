{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP3u0Q55P+x335660EehBfH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/201921027/graduate_project_git/blob/main/_gp_bart_recurrent_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* kobart 공식 깃헙\n",
        "\n",
        "https://github.com/SKT-AI/KoBART#examples\n",
        "\n",
        "https://github.com/seujung/KoBART-summarization"
      ],
      "metadata": {
        "id": "iH_o9u7I1nZk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. kobart 불러오기\n",
        "\n",
        "2. kobart fine-tuning에 맞게 훈련 데이터 형태 변환 (.tsv) (gp_bart_data_processing.ipynb에서 수행)\n",
        "\n",
        "3. kobart fine-tuning \n",
        "\n",
        "4. train된 kobart에 train set의 일기 데이터셋을 넣어 공감코멘트 생성 (.csv)\n",
        "\n",
        "5. (4)의 output으로 기존 kobart 모델 추가 train (데이터 되먹임)\n",
        "\n",
        "6. (4) ~ (5) 과정을 반복 (생성되는 공감코멘트가 어느정도의 성능으로 수렴할 때까지)"
      ],
      "metadata": {
        "id": "Hi67e5wG6Cbv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. kobart 불러오기 ~ 3. kobart fine-tuning"
      ],
      "metadata": {
        "id": "OgvwVYWM_-m9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# KoBART-summarization git 다운받고 -> \n",
        "# KoBART-summarization 내부의 data 디렉토리에 train, test.tsv data 파일(data/bart_train_data.tsv) 내 걸로 바꾸고 -> \n",
        "# KOBART의 requirment와 binary 인스톨 및 다운로드 하고 ->\n",
        "# KoBART의 python train.py 실행시켜 fine-tuning 수행: \n",
        "# !python train.py  --gradient_clip_val 1.0  \\\n",
        "#                  --max_epochs 50 \\\n",
        "#                  --default_root_dir logs \\\n",
        "#                  --gpus 1 \\\n",
        "#                  --batch_size 4 \\\n",
        "#                  --num_workers 4\n",
        "\n",
        "# train 후 생성되는 공감코멘트 quailty 확인"
      ],
      "metadata": {
        "id": "X2MlmWu153zQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VT103yAqAx3v",
        "outputId": "b32726ff-4c25-450f-ae81-34b4c64a00ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/MyDrive/Colab Notebooks/graduation_project'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qivZ4lNCOpl",
        "outputId": "e8ecdf2c-a10f-46e4-cd49-f00f8f6ae44b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/graduation_project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !git clone https://github.com/seujung/KoBART-summarization.git"
      ],
      "metadata": {
        "id": "nPORS3gZCX5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/MyDrive/Colab Notebooks/graduation_project/KoBART-summarization'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8HXM2EyCbnX",
        "outputId": "24e66f59-e6bd-4376-e878-1c54baf11ceb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/graduation_project/KoBART-summarization\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v89m9LK8DWj0",
        "outputId": "805412e2-031d-4dcc-e986-8695d4302bfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.3.5)\n",
            "Collecting torch==1.10.0\n",
            "  Downloading torch-1.10.0-cp37-cp37m-manylinux1_x86_64.whl (881.9 MB)\n",
            "\u001b[K     |██████████████████████████████▎ | 834.1 MB 1.1 MB/s eta 0:00:43tcmalloc: large alloc 1147494400 bytes == 0x6482e000 @  0x7f56f8d91615 0x58e046 0x4f2e5e 0x4d19df 0x51b31c 0x5b41c5 0x58f49e 0x51b221 0x5b41c5 0x58f49e 0x51837f 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4ba70a 0x538136 0x590055 0x51b180 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51740e 0x58f2a7 0x517947 0x5b41c5 0x58f49e\n",
            "\u001b[K     |████████████████████████████████| 881.9 MB 18 kB/s \n",
            "\u001b[?25hCollecting transformers==4.8.2\n",
            "  Downloading transformers-4.8.2-py3-none-any.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 78.7 MB/s \n",
            "\u001b[?25hCollecting pytorch-lightning==1.3.8\n",
            "  Downloading pytorch_lightning-1.3.8-py3-none-any.whl (813 kB)\n",
            "\u001b[K     |████████████████████████████████| 813 kB 76.8 MB/s \n",
            "\u001b[?25hCollecting streamlit==1.1.0\n",
            "  Downloading streamlit-1.1.0-py2.py3-none-any.whl (8.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.3 MB 48.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0->-r requirements.txt (line 2)) (4.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.2->-r requirements.txt (line 3)) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.2->-r requirements.txt (line 3)) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.2->-r requirements.txt (line 3)) (4.12.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 63.5 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub==0.0.12\n",
            "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.2->-r requirements.txt (line 3)) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.2->-r requirements.txt (line 3)) (3.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.2->-r requirements.txt (line 3)) (6.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 54.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.2->-r requirements.txt (line 3)) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.2->-r requirements.txt (line 3)) (2.23.0)\n",
            "Collecting future>=0.17.1\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 77.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard!=2.5.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (2.8.0)\n",
            "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (2022.8.2)\n",
            "Collecting pyDeprecate==0.3.0\n",
            "  Downloading pyDeprecate-0.3.0-py3-none-any.whl (10 kB)\n",
            "Collecting pyyaml\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 66.9 MB/s \n",
            "\u001b[?25hCollecting torchmetrics>=0.2.0\n",
            "  Downloading torchmetrics-0.9.3-py3-none-any.whl (419 kB)\n",
            "\u001b[K     |████████████████████████████████| 419 kB 92.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (7.1.2)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from streamlit==1.1.0->-r requirements.txt (line 5)) (22.1.0)\n",
            "Collecting validators\n",
            "  Downloading validators-0.20.0.tar.gz (30 kB)\n",
            "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.7/dist-packages (from streamlit==1.1.0->-r requirements.txt (line 5)) (4.2.4)\n",
            "Requirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit==1.1.0->-r requirements.txt (line 5)) (4.2.0)\n",
            "Collecting blinker\n",
            "  Downloading blinker-1.5-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.7/dist-packages (from streamlit==1.1.0->-r requirements.txt (line 5)) (5.1.1)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (from streamlit==1.1.0->-r requirements.txt (line 5)) (6.0.1)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from streamlit==1.1.0->-r requirements.txt (line 5)) (1.5.1)\n",
            "Requirement already satisfied: click<8.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from streamlit==1.1.0->-r requirements.txt (line 5)) (7.1.2)\n",
            "Requirement already satisfied: protobuf!=3.11,>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from streamlit==1.1.0->-r requirements.txt (line 5)) (3.17.3)\n",
            "Collecting gitpython!=3.1.19\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 78.5 MB/s \n",
            "\u001b[?25hCollecting pydeck>=0.1.dev5\n",
            "  Downloading pydeck-0.8.0b3-py2.py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 53.9 MB/s \n",
            "\u001b[?25hCollecting watchdog\n",
            "  Downloading watchdog-2.1.9-py3-none-manylinux2014_x86_64.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 7.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from streamlit==1.1.0->-r requirements.txt (line 5)) (0.10.2)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from streamlit==1.1.0->-r requirements.txt (line 5)) (0.8.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from streamlit==1.1.0->-r requirements.txt (line 5)) (2.8.2)\n",
            "Collecting base58\n",
            "  Downloading base58-2.1.1-py3-none-any.whl (5.6 kB)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 1)) (2022.2.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit==1.1.0->-r requirements.txt (line 5)) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit==1.1.0->-r requirements.txt (line 5)) (2.11.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit==1.1.0->-r requirements.txt (line 5)) (4.3.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit==1.1.0->-r requirements.txt (line 5)) (0.12.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (3.8.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (1.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (1.8.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (2.1.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (0.13.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (6.0.2)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.0 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit==1.1.0->-r requirements.txt (line 5)) (0.18.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit==1.1.0->-r requirements.txt (line 5)) (5.9.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=3.0->altair>=3.2.0->streamlit==1.1.0->-r requirements.txt (line 5)) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.8.2->-r requirements.txt (line 3)) (3.0.9)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf!=3.11,>=3.6.0->streamlit==1.1.0->-r requirements.txt (line 5)) (1.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->altair>=3.2.0->streamlit==1.1.0->-r requirements.txt (line 5)) (2.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (0.6.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (3.4.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (57.4.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (1.48.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (1.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (0.37.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (1.35.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.8.2->-r requirements.txt (line 3)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.8.2->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.8.2->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.8.2->-r requirements.txt (line 3)) (2022.6.15)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r requirements.txt (line 4)) (3.2.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.8.2->-r requirements.txt (line 3)) (1.1.0)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from validators->streamlit==1.1.0->-r requirements.txt (line 5)) (4.4.2)\n",
            "Building wheels for collected packages: future, sacremoses, validators\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=e0a19ef809c3cdec0c561d665876f121cc639ea93a0a9e19c687a31784f02fe9\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=11c9c6ae2e8313b8a61e3790ba2ce5426be2fd1f6653398c948acdfb20ae23ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for validators: filename=validators-0.20.0-py3-none-any.whl size=19582 sha256=f10d84295fc845291814d6ce431bcf40b44ec0ecee5c7eaeae57e019491d7334\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/55/ab/36a76989f7f88d9ca7b1f68da6d94252bb6a8d6ad4f18e04e9\n",
            "Successfully built future sacremoses validators\n",
            "Installing collected packages: smmap, torch, gitdb, watchdog, validators, torchmetrics, tokenizers, sacremoses, pyyaml, pyDeprecate, pydeck, huggingface-hub, gitpython, future, blinker, base58, transformers, streamlit, pytorch-lightning\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.10.0 which is incompatible.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.10.0 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.10.0 which is incompatible.\u001b[0m\n",
            "Successfully installed base58-2.1.1 blinker-1.5 future-0.18.2 gitdb-4.0.9 gitpython-3.1.27 huggingface-hub-0.0.12 pyDeprecate-0.3.0 pydeck-0.8.0b3 pytorch-lightning-1.3.8 pyyaml-5.4.1 sacremoses-0.0.53 smmap-5.0.0 streamlit-1.1.0 tokenizers-0.10.3 torch-1.10.0 torchmetrics-0.9.3 transformers-4.8.2 validators-0.20.0 watchdog-2.1.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics==0.6.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lF5S4fRIz_r",
        "outputId": "2f5ac55c-2842-4c88-c0ae-d23bc4901184"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics==0.6.0\n",
            "  Downloading torchmetrics-0.6.0-py3-none-any.whl (329 kB)\n",
            "\u001b[K     |████████████████████████████████| 329 kB 14.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics==0.6.0) (1.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics==0.6.0) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics==0.6.0) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.1->torchmetrics==0.6.0) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics==0.6.0) (3.0.9)\n",
            "Installing collected packages: torchmetrics\n",
            "  Attempting uninstall: torchmetrics\n",
            "    Found existing installation: torchmetrics 0.9.3\n",
            "    Uninstalling torchmetrics-0.9.3:\n",
            "      Successfully uninstalled torchmetrics-0.9.3\n",
            "Successfully installed torchmetrics-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OSError\n",
        "# https://momozzing.github.io/error%20resolution/torchtext-OSError/\n",
        "# https://github.com/pytorch/text/issues/1342#issuecomment-993928516\n",
        "# UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: \n",
        "# https://programmerah.com/solved-torchvision-error-userwarning-failed-to-load-image-python-extension-could-not-find-module-48667/\n",
        "!pip install torchtext==0.11.0\n",
        "!pip install torchvision==0.11.2\n",
        "!pip install torchaudio===0.10.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3GcRN2ZLVfE",
        "outputId": "dae58dbf-6b15-4fbf-dc9b-bb13e9a9de18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.11.0\n",
            "  Downloading torchtext-0.11.0-cp37-cp37m-manylinux1_x86_64.whl (8.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.0 MB 11.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.11.0) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.11.0) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.11.0) (1.21.6)\n",
            "Requirement already satisfied: torch==1.10.0 in /usr/local/lib/python3.7/dist-packages (from torchtext==0.11.0) (1.10.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0->torchtext==0.11.0) (4.1.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.11.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.11.0) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.11.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.11.0) (2.10)\n",
            "Installing collected packages: torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.13.1\n",
            "    Uninstalling torchtext-0.13.1:\n",
            "      Successfully uninstalled torchtext-0.13.1\n",
            "Successfully installed torchtext-0.11.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchvision==0.11.2\n",
            "  Downloading torchvision-0.11.2-cp37-cp37m-manylinux1_x86_64.whl (23.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.3 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.11.2) (1.21.6)\n",
            "Collecting torch==1.10.1\n",
            "  Downloading torch-1.10.1-cp37-cp37m-manylinux1_x86_64.whl (881.9 MB)\n",
            "\u001b[K     |██████████████████████████████▎ | 834.1 MB 1.2 MB/s eta 0:00:42tcmalloc: large alloc 1147494400 bytes == 0x3a196000 @  0x7f57b5392615 0x58e046 0x4f2e5e 0x4d19df 0x51b31c 0x5b41c5 0x58f49e 0x51b221 0x5b41c5 0x58f49e 0x51837f 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4ba70a 0x538136 0x590055 0x51b180 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51740e 0x58f2a7 0x517947 0x5b41c5 0x58f49e\n",
            "\u001b[K     |████████████████████████████████| 881.9 MB 15 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.11.2) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.1->torchvision==0.11.2) (4.1.1)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0\n",
            "    Uninstalling torch-1.10.0:\n",
            "      Successfully uninstalled torch-1.10.0\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.13.1+cu113\n",
            "    Uninstalling torchvision-0.13.1+cu113:\n",
            "      Successfully uninstalled torchvision-0.13.1+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.10.1 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.10.1 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.10.1 torchvision-0.11.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchaudio===0.10.1\n",
            "  Downloading torchaudio-0.10.1-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 13.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch==1.10.1 in /usr/local/lib/python3.7/dist-packages (from torchaudio===0.10.1) (1.10.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.1->torchaudio===0.10.1) (4.1.1)\n",
            "Installing collected packages: torchaudio\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.12.1+cu113\n",
            "    Uninstalling torchaudio-0.12.1+cu113:\n",
            "      Successfully uninstalled torchaudio-0.12.1+cu113\n",
            "Successfully installed torchaudio-0.10.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# AttributeError: 'Trainer' object has no attribute '_data_connector'\n",
        "# https://zorba-blog.tistory.com/23\n",
        "!pip install pytorch_lightning==1.5.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwosFqyCO0PJ",
        "outputId": "78ed590f-ee02-416d-e50b-35a99c25b272"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch_lightning==1.5.2\n",
            "  Downloading pytorch_lightning-1.5.2-py3-none-any.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 15.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.5.2) (4.64.1)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.5.2) (5.4.1)\n",
            "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.5.2) (2022.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.5.2) (1.21.6)\n",
            "Collecting pyDeprecate==0.3.1\n",
            "  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.5.2) (1.10.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.5.2) (21.3)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.5.2) (2.8.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.5.2) (4.1.1)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.5.2) (0.18.2)\n",
            "Requirement already satisfied: torchmetrics>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.5.2) (0.6.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.2) (3.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.2) (2.23.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.2) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.2) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.2) (6.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.2) (1.8.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.2) (2.1.1)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.2) (0.13.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.2) (1.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.2) (22.1.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch_lightning==1.5.2) (3.0.9)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.5.2) (1.48.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.5.2) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.5.2) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.5.2) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.5.2) (0.37.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.5.2) (0.6.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.5.2) (3.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.5.2) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.5.2) (3.4.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.5.2) (57.4.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.5.2) (1.2.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.5.2) (1.15.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.5.2) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.5.2) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.5.2) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning==1.5.2) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning==1.5.2) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning==1.5.2) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.5.2) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.2) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.2) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.2) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.2) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning==1.5.2) (3.2.0)\n",
            "Installing collected packages: pyDeprecate, pytorch-lightning\n",
            "  Attempting uninstall: pyDeprecate\n",
            "    Found existing installation: pyDeprecate 0.3.0\n",
            "    Uninstalling pyDeprecate-0.3.0:\n",
            "      Successfully uninstalled pyDeprecate-0.3.0\n",
            "  Attempting uninstall: pytorch-lightning\n",
            "    Found existing installation: pytorch-lightning 1.3.8\n",
            "    Uninstalling pytorch-lightning-1.3.8:\n",
            "      Successfully uninstalled pytorch-lightning-1.3.8\n",
            "Successfully installed pyDeprecate-0.3.1 pytorch-lightning-1.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.version\n",
        "# pyyhon 3.7.x version으로 맞출 것"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Ajz0Gp2xMy8i",
        "outputId": "9d415e44-0baa-4c6f-8f53-5063ec1050ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.7.14 (default, Sep  8 2022, 00:06:44) \\n[GCC 7.5.0]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 기존 max_epochs=50\n",
        "# train, test data를 내 data로 수정하여 실행하기\n",
        "!python train.py  --gradient_clip_val 1.0  \\\n",
        "                 --max_epochs 10 \\\n",
        "                 --default_root_dir logs \\\n",
        "                 --gpus 1 \\\n",
        "                 --batch_size 4 \\\n",
        "                 --num_workers 4 \\\n",
        "                 --model_path '/content/drive/MyDrive/Colab Notebooks/graduation_project/KoBART-summarization/logs/model_chp/epoch=02-val_loss=3.203.ckpt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lZ83OFrEKcb",
        "outputId": "8e98ce91-6f53-496f-cde6-f113310f92dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: 100% 4.00/4.00 [00:00<00:00, 4.33kB/s]\n",
            "Downloading: 100% 111/111 [00:00<00:00, 111kB/s]\n",
            "Downloading: 100% 682k/682k [00:00<00:00, 1.98MB/s]\n",
            "INFO:root:Namespace(accelerator=None, accumulate_grad_batches=None, amp_backend='native', amp_level=None, auto_lr_find=False, auto_scale_batch_size=False, auto_select_gpus=False, batch_size=4, benchmark=False, check_val_every_n_epoch=1, checkpoint_callback=None, checkpoint_path=None, default_root_dir='logs', detect_anomaly=False, deterministic=False, devices=None, enable_checkpointing=True, enable_model_summary=True, enable_progress_bar=True, fast_dev_run=False, flush_logs_every_n_steps=None, gpus=1, gradient_clip_algorithm=None, gradient_clip_val=1.0, ipus=None, limit_predict_batches=1.0, limit_test_batches=1.0, limit_train_batches=1.0, limit_val_batches=1.0, log_every_n_steps=50, log_gpu_memory=None, logger=True, lr=3e-05, max_epochs=10, max_len=512, max_steps=-1, max_time=None, min_epochs=None, min_steps=None, model_path='/content/drive/MyDrive/Colab Notebooks/graduation_project/KoBART-summarization/logs/model_chp/epoch=02-val_loss=3.203.ckpt', move_metrics_to_cpu=False, multiple_trainloader_mode='max_size_cycle', num_nodes=1, num_processes=1, num_sanity_val_steps=2, num_workers=4, overfit_batches=0.0, plugins=None, precision=32, prepare_data_per_node=None, process_position=0, profiler=None, progress_bar_refresh_rate=None, reload_dataloaders_every_epoch=False, reload_dataloaders_every_n_epochs=0, replace_sampler_ddp=True, resume_from_checkpoint=None, stochastic_weight_avg=False, strategy=None, sync_batchnorm=False, terminate_on_nan=None, test_file='data/test.tsv', tpu_cores=None, track_grad_norm=-1, train_file='data/train.tsv', val_check_interval=1.0, warmup_ratio=0.1, weights_save_path=None, weights_summary='top')\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "Downloading: 100% 1.36k/1.36k [00:00<00:00, 1.49MB/s]\n",
            "Downloading: 100% 496M/496M [00:12<00:00, 39.4MB/s]\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:root:number of workers 4, data length 242\n",
            "INFO:root:num_train_steps : 151\n",
            "INFO:root:num_warmup_steps : 15\n",
            "\n",
            "  | Name  | Type                         | Params\n",
            "-------------------------------------------------------\n",
            "0 | model | BartForConditionalGeneration | 123 M \n",
            "-------------------------------------------------------\n",
            "123 M     Trainable params\n",
            "0         Non-trainable params\n",
            "123 M     Total params\n",
            "495.440   Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory /content/drive/MyDrive/Colab Notebooks/graduation_project/KoBART-summarization/logs exists and is not empty.\n",
            "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
            "Epoch 0: 100% 250/250 [02:26<00:00,  1.71it/s, loss=0.768, v_num=9, train_loss=1.560]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 0: 100% 250/250 [02:27<00:00,  1.69it/s, loss=0.771, v_num=9, train_loss=0.973, val_loss=2.950]\n",
            "                                             \u001b[AEpoch 0, global step 241: val_loss reached 2.95484 (best 2.95484), saving model to \"/content/drive/MyDrive/Colab Notebooks/graduation_project/KoBART-summarization/logs/model_chp/epoch=00-val_loss=2.955.ckpt\" as top 3\n",
            "tcmalloc: large alloc 1075716096 bytes == 0xc04ba000 @  0x7fc553750615 0x58e046 0x4f2e5e 0x58ee1f 0x58f096 0x7fc53b9755e4 0x7fc53b97d714 0x7fc53b952660 0x7fc526b297f5 0x7fc526b2512e 0x7fc526b2cad5 0x7fc53b952bae 0x7fc53b0c96a8 0x58ec54 0x58fc01 0x51b7fd 0x5b4a3e 0x58f49e 0x51740e 0x5b41c5 0x58f49e 0x51b221 0x58f2a7 0x51740e 0x5b41c5 0x58f49e 0x517947 0x58f2a7 0x517947 0x5b41c5 0x58f49e\n",
            "tcmalloc: large alloc 1344651264 bytes == 0x12d1d4000 @  0x7fc553750615 0x58e046 0x4f2e5e 0x58ee1f 0x58f096 0x7fc53b9755e4 0x7fc53b97d714 0x7fc53b952660 0x7fc526b297f5 0x7fc526b2512e 0x7fc526b2cad5 0x7fc53b952bae 0x7fc53b0c96a8 0x58ec54 0x58fc01 0x51b7fd 0x5b4a3e 0x58f49e 0x51740e 0x5b41c5 0x58f49e 0x51b221 0x58f2a7 0x51740e 0x5b41c5 0x58f49e 0x517947 0x58f2a7 0x517947 0x5b41c5 0x58f49e\n",
            "tcmalloc: large alloc 1680818176 bytes == 0xc04ba000 @  0x7fc553750615 0x58e046 0x4f2e5e 0x58ee1f 0x58f096 0x7fc53b9755e4 0x7fc53b97d714 0x7fc53b952660 0x7fc526b297f5 0x7fc526b2512e 0x7fc526b2cad5 0x7fc53b952bae 0x7fc53b0c96a8 0x58ec54 0x58fc01 0x51b7fd 0x5b4a3e 0x58f49e 0x51740e 0x5b41c5 0x58f49e 0x51b221 0x58f2a7 0x51740e 0x5b41c5 0x58f49e 0x517947 0x58f2a7 0x517947 0x5b41c5 0x58f49e\n",
            "tcmalloc: large alloc 1680818176 bytes == 0x12d1d4000 @  0x7fc553750615 0x58e046 0x4f2e5e 0x58ee1f 0x58f096 0x7fc53b9755e4 0x7fc53b97d714 0x7fc53b952660 0x7fc526b297f5 0x7fc526b2512e 0x7fc526b2cad5 0x7fc53b952bae 0x7fc53b0c96a8 0x58ec54 0x58fc01 0x51b7fd 0x5b4a3e 0x58f49e 0x51740e 0x5b41c5 0x58f49e 0x51b221 0x58f2a7 0x51740e 0x5b41c5 0x58f49e 0x517947 0x58f2a7 0x517947 0x5b41c5 0x58f49e\n",
            "Epoch 1: 100% 250/250 [02:29<00:00,  1.67it/s, loss=0.419, v_num=9, train_loss=0.0607, val_loss=2.950]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1: 100% 250/250 [02:31<00:00,  1.65it/s, loss=0.409, v_num=9, train_loss=0.371, val_loss=3.130] \n",
            "                                             \u001b[AEpoch 1, global step 483: val_loss reached 3.12765 (best 2.95484), saving model to \"/content/drive/MyDrive/Colab Notebooks/graduation_project/KoBART-summarization/logs/model_chp/epoch=01-val_loss=3.128.ckpt\" as top 3\n",
            "Epoch 2: 100% 250/250 [02:30<00:00,  1.67it/s, loss=0.28, v_num=9, train_loss=0.0891, val_loss=3.130]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2: 100% 250/250 [02:32<00:00,  1.64it/s, loss=0.282, v_num=9, train_loss=0.100, val_loss=3.340]\n",
            "                                             \u001b[AEpoch 2, global step 725: val_loss reached 3.33608 (best 2.95484), saving model to \"/content/drive/MyDrive/Colab Notebooks/graduation_project/KoBART-summarization/logs/model_chp/epoch=02-val_loss=3.336.ckpt\" as top 3\n",
            "Epoch 3: 100% 250/250 [02:30<00:00,  1.67it/s, loss=0.176, v_num=9, train_loss=0.105, val_loss=3.340]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 3: 100% 250/250 [02:32<00:00,  1.64it/s, loss=0.148, v_num=9, train_loss=0.00676, val_loss=3.510]\n",
            "                                             \u001b[AEpoch 3, global step 967: val_loss was not in top 3\n",
            "Epoch 4: 100% 250/250 [02:30<00:00,  1.67it/s, loss=0.15, v_num=9, train_loss=0.0881, val_loss=3.510]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 4: 100% 250/250 [02:32<00:00,  1.64it/s, loss=0.138, v_num=9, train_loss=0.0791, val_loss=3.650]\n",
            "                                             \u001b[AEpoch 4, global step 1209: val_loss was not in top 3\n",
            "Epoch 5: 100% 250/250 [02:30<00:00,  1.67it/s, loss=0.0751, v_num=9, train_loss=0.0373, val_loss=3.650]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 5: 100% 250/250 [02:32<00:00,  1.64it/s, loss=0.091, v_num=9, train_loss=0.278, val_loss=3.750]  \n",
            "                                             \u001b[AEpoch 5, global step 1451: val_loss was not in top 3\n",
            "Epoch 6: 100% 250/250 [02:30<00:00,  1.67it/s, loss=0.0902, v_num=9, train_loss=0.162, val_loss=3.750]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 6: 100% 250/250 [02:32<00:00,  1.64it/s, loss=0.0917, v_num=9, train_loss=0.089, val_loss=3.850]\n",
            "                                             \u001b[AEpoch 6, global step 1693: val_loss was not in top 3\n",
            "Epoch 7: 100% 250/250 [02:29<00:00,  1.67it/s, loss=0.052, v_num=9, train_loss=0.123, val_loss=3.850]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 7: 100% 250/250 [02:32<00:00,  1.64it/s, loss=0.055, v_num=9, train_loss=0.0171, val_loss=3.900]\n",
            "                                             \u001b[AEpoch 7, global step 1935: val_loss was not in top 3\n",
            "Epoch 8: 100% 250/250 [02:30<00:00,  1.67it/s, loss=0.0377, v_num=9, train_loss=0.0434, val_loss=3.900]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 8: 100% 250/250 [02:32<00:00,  1.64it/s, loss=0.0355, v_num=9, train_loss=0.0257, val_loss=3.990]\n",
            "                                             \u001b[AEpoch 8, global step 2177: val_loss was not in top 3\n",
            "Epoch 9: 100% 250/250 [02:29<00:00,  1.67it/s, loss=0.0492, v_num=9, train_loss=0.00589, val_loss=3.990]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9: 100% 250/250 [02:32<00:00,  1.64it/s, loss=0.0457, v_num=9, train_loss=0.0356, val_loss=3.990] \n",
            "                                             \u001b[AEpoch 9, global step 2419: val_loss was not in top 3\n",
            "Epoch 9: 100% 250/250 [02:41<00:00,  1.55it/s, loss=0.0457, v_num=9, train_loss=0.0356, val_loss=3.990]\n",
            "Saving latest checkpoint...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### test + 4. train된 kobart에 train set의 일기 데이터셋을 넣어 공감코멘트 생성 (.csv)"
      ],
      "metadata": {
        "id": "I40xWnzjUHVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "def drop_na(df):\n",
        "  df= df.dropna()\n",
        "  df= df.reset_index(drop=True)\n",
        "  return df"
      ],
      "metadata": {
        "id": "804lI-YwZCh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import PreTrainedTokenizerFast\n",
        "from transformers import BartForConditionalGeneration\n",
        "\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained('digit82/kobart-summarization')"
      ],
      "metadata": {
        "id": "7z_B8N3nHhJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BartForConditionalGeneration.from_pretrained('digit82/kobart-summarization') # fine-tuning된 모델로"
      ],
      "metadata": {
        "id": "N85UZFDZeT8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hparam_path= '/content/drive/MyDrive/Colab Notebooks/graduation_project/KoBART-summarization/logs/tb_logs/default/version_0/hparams.yaml'\n",
        "# model_binary_path= '/content/drive/MyDrive/Colab Notebooks/graduation_project/KoBART-summarization/logs/model_chp/epoch=00-val_loss=2.590.ckpt'"
      ],
      "metadata": {
        "id": "k2y1xtVWgeBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !python get_model_binary.py --hparams '/content/drive/MyDrive/Colab Notebooks/graduation_project/KoBART-summarization/logs/tb_logs/default/version_0/hparams.yaml' \\\n",
        "#                             --model_binary '/content/drive/MyDrive/Colab Notebooks/graduation_project/KoBART-summarization/logs/model_chp/epoch=00-val_loss=2.590.ckpt'"
      ],
      "metadata": {
        "id": "ZNvmpef5gE8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !streamlit run infer.py"
      ],
      "metadata": {
        "id": "D5_Inau7gvSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/graduation_project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ej_TQEPJe3JW",
        "outputId": "50af74eb-b5ac-4a71-e709-190301f736cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/graduation_project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.10.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxnTLmsikpfB",
        "outputId": "a3769bea-1bb1-42ee-bb74-d3257d32cd89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers==4.10.1 in /usr/local/lib/python3.7/dist-packages (4.10.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.1) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.1) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.1) (3.8.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.1) (5.4.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.1) (1.21.6)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.1) (0.0.12)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.1) (4.12.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.1) (0.10.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.1) (0.0.53)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.1) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.1) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers==4.10.1) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.10.1) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.10.1) (3.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.10.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.10.1) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.10.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.10.1) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.10.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.10.1) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.10.1) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_lightning as pl"
      ],
      "metadata": {
        "id": "9I2RFs3skIdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BartModel(pl.LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = BartForConditionalGeneration.from_pretrained('digit82/kobart-summarization')  \n",
        "      \n",
        "    def forward(self):\n",
        "        pass\n",
        " \n",
        "# 불러올 모델 파일 바꾸기\n",
        "ckpt = torch.load('/content/drive/MyDrive/Colab Notebooks/graduation_project/KoBART-summarization/logs/model_chp/epoch=02-val_loss=3.203.ckpt')\n",
        "   \n",
        "bart_model = BartModel()\n",
        "bart_model.load_state_dict(ckpt['state_dict'])\n",
        "bart_model.model.save_pretrained(\"./KoBART-summarization/logs/model_chp\")"
      ],
      "metadata": {
        "id": "VE_qSf-Qjg6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BartForConditionalGeneration.from_pretrained('./KoBART-summarization/logs/model_chp')"
      ],
      "metadata": {
        "id": "RU48X_DKemDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- test"
      ],
      "metadata": {
        "id": "mLNE_8OwU-rO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data= pd.read_csv('/content/drive/MyDrive/Colab Notebooks/graduation_project/KoBART-summarization/data/test.tsv', sep='\\t')\n",
        "test_data= test_data[['news']] # test_text\n",
        "\n",
        "test_data= drop_na(test_data)"
      ],
      "metadata": {
        "id": "mFERJXDyUmIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_list = test_data['news']\n",
        "summary_list=list()"
      ],
      "metadata": {
        "id": "j7iN4nbTV4T4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_list = test_data['news']\n",
        "summary_list=list()\n",
        "\n",
        "for i, text in enumerate(text_list):\n",
        "  if len(text) + len(\" TL;DR \") > 800:\n",
        "    text = text[0:400] + text[len(text)-400:len(text)]\n",
        "  text= text + \" TL;DR \"\n",
        "\n",
        "  text = text.replace('\\n', ' ')\n",
        "\n",
        "  raw_input_ids = tokenizer.encode(text)\n",
        "  input_ids = [tokenizer.bos_token_id] + raw_input_ids + [tokenizer.eos_token_id]\n",
        "\n",
        "  summary_ids = model.generate(torch.tensor([input_ids]),  num_beams=4,  max_length=512,  eos_token_id=1)\n",
        "  output= tokenizer.decode(summary_ids.squeeze().tolist(), skip_special_tokens=True)\n",
        "  summary_list.append(output)\n",
        "  if i%10 == 0:\n",
        "    print('test {} 개 진행중'.format(i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_m2owcIIUeKv",
        "outputId": "bd3d083e-b38e-442e-8795-12065ec7cb8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test 0 개 진행중\n",
            "test 10 개 진행중\n",
            "test 20 개 진행중\n",
            "test 30 개 진행중\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhEoF1FgWl0A",
        "outputId": "0503d6bc-7496-4797-a48e-c08255603718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['나를 사랑하는하는 연습 어떻게 하면 나를 사랑할 수 있을까요? 자책하는 습관부터 버려야 돼요. 자책하는 습관부터 버려야 돼요. 자책은 사실 나를 갉아 먹는 일이거든, 자책하는 습관부터 버려야 돼요.',\n",
              " '일본어를 어디서 배웠는지, 뭐 하려고 이 호텔에 왔는지 그런 질문에 답을 해줘야 했군요. 정말 화가 났을 것 같아요. 그래도 김동률 콘서트는 정말 멋진 공연이었다니 다행이에요.',\n",
              " '수간호사선선생님의 ot를 간단히 들으셨군요. 바이탈사인을 척정하고 이브 루틴 바이탈우지보다 안좋은 상태인 것 같아요. 빨리 상황이 나아졌으면 좋겠어요.',\n",
              " '반포한강에 다녀오셨군요! 한강에서 남준이를 마주치는 상상도 해보고, 야경이 아름다웠으면 좋겠네요.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ',\n",
              " '아버지와 둘이 햄버거를 먹으셨군요. 저도 햄버거를 먹었으면 좋겠네요.',\n",
              " '오늘 밤 미치려고 작정한 것 같아요. 욕을 안하고 글을 쓸 수가 없어서 부끄럽고요. 그래도 좋은 사람이 생기길 바랄게요.',\n",
              " '강아지와 고양이를 미용하는 애견미용사(펫 스타일리스트)이시군요. 분명 잘 할 수 있을 거에요!',\n",
              " '어릴적부터 요리를 잘해서 디저트에도 관심이 생겼고 직접 만들어보고싶은 충동을 가지셨군요. 베이킹도 요리에 속하긴 하지만 지금껏 만들던 것들과는 차원이 다르게 힘든 것 같아요. 베이킹도 요리에 속하긴 하지만 정확한 계량에서 어긋나면 맛과 모양이 완전히 틀어지는것 같아요. 그래도 마카롱을 참 좋아하시는군요. 베이킹도 요리에 속하긴 하지만 기본적인 재료로 가장 고급진 식감과 겉면을 만들어내야 하기에 더 힘든 것 같아요.',\n",
              " '어렸을때는 변호사를 꿈꿨었군요. 카페가 젤 가고싶은데 못 나가서 너무 답답할 것 같아요. 젤 가고싶은데도 못 나가서 너무 답답할 것 같아요. 젤 가고싶은데도 못 나가서 너무 답답할 것 같아요.                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ',\n",
              " '작년의 끝자락이라 머리가 무겁고 기분이 잔뜩 가라앉은 날이셨군요. 위로가 필요할 땐 주위를 둘러보는 건 어떨까요?',\n",
              " '결국 어린 시절을 보낸 곳에서 팔려 떠나게 되었을 때 조차 그 어린 시절의 추억과 작별하게 된 것이 오히려 기뻤다고 하니, 정말 기뻤을 것 같아요.',\n",
              " '처음 운전면허 학원에 등록 하러 갔던 날은 정말 힘들었을 것 같아요. 셔틀 번호 찾아서 연락하고, 시간 맞춰 셔틀 타기로 한 곳에 서서 기다렸다니 정말 다행이에요.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ',\n",
              " '방탄소년단 공연에 당첨이 되는 사람과 한번도 당첨되지 않은 사람의 비율이 꽤 많은 것 같아 속상할 것 같아요. 그래도 팬들과 소통할 수 있길 바랄게요.',\n",
              " '혼자 유럽 유럽여행을 다녀오셨군요! 아쉬움도 남았지만 무사히 다녀왔다니 다행이에요. 앞으로 어떤 일이든 혼자서 다 잘 해낼 수 있을 거란 자신감이 생겼을 거에요!',\n",
              " '태국으로 여행지를 정하게 되기까지 아주 많은 후보지와 변경이 있었군요. 다낭이 추워서 영 수영할 수 있는 날씨가 아니라고 하니, 다낭이 추워서 영 수영할 수 있는 날씨가 아니라고 하니, 정말 다행이에요.',\n",
              " '예멘 난민을 다루기 위해서는 난민에 대한 공부가 필수불가결하니까요.',\n",
              " '매번 반복되는 일상에 지치고 힘들었지만 국시에 합격하지 못할까봐 그 불안감이 당신을 버티게 만들었던 것 같아요. 그래도 옆에서 같이 공부하는 친구들이 있어서 위로가 되었다니 다행이에요.',\n",
              " '복지원에서 봉사활동을 하고 계시는군요. 분명 좋은 결과가 있을 거에요!',\n",
              " \"좋아하는 가수 윤하의 새 앨범이 발표됐군요. 팬클럽 가입 키트에 '다이어리'가 있는 덕분에 생전 써본 적 없던 일기를 이렇게 자발적으로 쓰고 계시는군요. 분명 수익창출까지 갈 수 있을 거에요!\",\n",
              " '취미도 없고 삶의 의미도 없었던 나는 약 3개월을 식음을 전폐하고 집에 틀어박혀 지냈군요. 최애를 좋아하게 된 것이 정말 다행이에요. 최애를 좋아하게 된 것이 정말 다행이에요.',\n",
              " \"대학교 2학년 2학년 때 대학교 2학년을 돌아보면서 '나는 참 이룬 것이 없구나' 하는 생각이 들었군요. 연말이 다가오면 지나간 그 해를 뒤돌아보며 후회하는 것 같아요. 당신의 말대로, 당신은 분명 잘 해낼 수 있을 것이라고 믿어요.\",\n",
              " '시골에서 자라서 그런지 시장을 참 좋아하시는군요! 저도 한번 구경해보고 싶네요!',\n",
              " '무기력과 무관심이 나의 일부분이라고 생각해왔던 20여년의 세월과는 달리 작년의 2019년은 유독 무기력과 무관심이 나를 갉아먹었던 시간이었군요. 새로운 환경과 관계에 도전해보고 싶었던 당신은 분명 잘 해낼 수 있을 것이라고 믿어요.',\n",
              " '날씨가 좋아서 좋으시군요! 저도 한번 가보고 싶네요!',\n",
              " '얼떨결에 시작한 연애를 서툰 사랑에서 진정한 사랑까지 찾는 그런 계절을 맞이하길 바랄게요.',\n",
              " '오래 동면에 잠든 짐승처럼 오랫동안 슬픔에 잠겨 계시는군요. 분명 좋은 사람이 될 수 있을 거에요 힘내세요!',\n",
              " '중학교를 다닐 때는 한 달에 오 만원 정도의 용돈을 받아서 절반은 교통카드 충전을, 또 절반은 친구들과 노는 곳에 주로 썼었군요. 고등학교를 다닐 때는 돈이 모자르게만 느껴져서 아르바이트를 통해 부족한 돈을 충당하기보다는 버스를 타는 것 대신 삼십여분거리를 걸어서 등하교를 하고 그 교통비를 용돈에 보태서 쓰는 방법을 겁도 많이 났었지만 지금은 한 번 해보자라는 마음으로 첫 출근을 해서 일 년간 꾸준히 빵집 아르바이트를 통해 저축도 하고 부모님께 선물도 사 드리고 보람찬 일들을 많이 했군요. 분명 큰 것도 소중히 여겨 아낄 줄 아는 마음을 가진 당신이 될 수 있을 거에요!',\n",
              " '프로젝트 팀원이 갑작스럽게 무단 퇴사를 했군요. 회사에 대한 최소한의 예의가 있는 사람이라면 아무렇지 않은 척 인사를 할 것이라고 생각해요. 당신의 말대로, 당신의 인계 받을 사항에 대해 정확히 안내 받지 못한 상태에서, 당신의 회사가 수습하지 못한 일들은 해결해야 한다고 생각해요. 당신의 말대로, 당신의 인계 받을 사항에 대해 정확히 안내 받지 못한 상태에서, 당신의 회사가 수습하지 못한 일들은 해결해야 한다고 생각해요. 당신의 말대로, 당신의 인계 받을 사항에 대해 정확히 안내 받지 못한 상태에서, 당신의 회사가 수습하지 못한 일들은 해결해야 한다고 생각해요. 당신의 회사가 수습하지 못한 일들을 해결해야 한다는 것은 정말 어려운 일인 것 같아요. 당신의 말대로, 당신의 인계 기간을 충분히 고려하여 무탈하게 인수인계가 진행될 수 있도록 했으면 좋겠어요.',\n",
              " '코로나 때문인 것 같아요. 코로나 때문인 것 같아요. 사람들이 점점 늘어나서 장사가 안되서 곧 짤리지 않을까 걱정이 많으시군요. 분명 좋은 아르바이트가 될 거에요 힘내세요!',\n",
              " '월급은 쥐꼬리만해서 일할 맛은 1도 안나는데 출근 중이라니 너무 슬프시겠어요. 빨리 돈이 나와서 편안한 밤이 되길 바래요!',\n",
              " '코로나로 인해 많은 일들과 부딛히게 되었군요. 코로나 때문에 힘들었을 것 같아요. 코로나 때문에 힘들었을 것 같아요. 당신의 남자친구가 코로나에 걸리셨다니 정말 속상할 것 같아요. 당신의 남자친구가 코로나에 걸리셨다니 정말 속상할 것 같아요. 당신의 남자친구가 코로나에 걸리지 않았다니 정말 다행이에요. 당신의 남자친구가 코로나에 걸리지 않았다니 정말 다행이에요.']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data['summary'] = summary_list"
      ],
      "metadata": {
        "id": "x5cdeTxtXWrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# >>>>>>>>>>>>>>>>>>>>>> 훈련 반복할 때마다 파일명 바꾸기 default -> 1 -> 2...\n",
        "test_data.to_csv('/content/drive/MyDrive/Colab Notebooks/graduation_project/kobart-kogpt_output/kobart_test_2.csv') "
      ],
      "metadata": {
        "id": "XtzPpo6wXZv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "test 결과 보고 -> train된 kobart에 train set의 일기 데이터셋을 넣어 공감코멘트 생성 (.csv)"
      ],
      "metadata": {
        "id": "ev8vLU6hXO1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "next_data= pd.read_csv('/content/drive/MyDrive/Colab Notebooks/graduation_project/KoBART-summarization/data/train.tsv', sep='\\t')\n",
        "next_data= next_data[['news']]\n",
        "\n",
        "next_data= drop_na(next_data)"
      ],
      "metadata": {
        "id": "jzYRivkjXOXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_list = next_data['news']\n",
        "summary_list=list()"
      ],
      "metadata": {
        "id": "HRBr6ldwYgQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_list = next_data['news']\n",
        "summary_list=list()\n",
        "\n",
        "for i, text in enumerate(text_list):\n",
        "  if len(text) + len(\" TL;DR \") > 800:\n",
        "    text = text[0:400] + text[len(text)-400:len(text)]\n",
        "  text= text + \" TL;DR \"\n",
        "\n",
        "  text = text.replace('\\n', ' ')\n",
        "\n",
        "  raw_input_ids = tokenizer.encode(text)\n",
        "  input_ids = [tokenizer.bos_token_id] + raw_input_ids + [tokenizer.eos_token_id]\n",
        "\n",
        "  summary_ids = model.generate(torch.tensor([input_ids]),  num_beams=4,  max_length=512,  eos_token_id=1)\n",
        "  output= tokenizer.decode(summary_ids.squeeze().tolist(), skip_special_tokens=True)\n",
        "  summary_list.append(output)\n",
        "  if i%10 == 0:\n",
        "    print('{} 개 진행중'.format(i))"
      ],
      "metadata": {
        "id": "BkSt7YU_Yj5G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7f9551e-8303-4fd2-8fdd-42019e68991b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 개 진행중\n",
            "10 개 진행중\n",
            "20 개 진행중\n",
            "30 개 진행중\n",
            "40 개 진행중\n",
            "50 개 진행중\n",
            "60 개 진행중\n",
            "70 개 진행중\n",
            "80 개 진행중\n",
            "90 개 진행중\n",
            "100 개 진행중\n",
            "110 개 진행중\n",
            "120 개 진행중\n",
            "130 개 진행중\n",
            "140 개 진행중\n",
            "150 개 진행중\n",
            "160 개 진행중\n",
            "170 개 진행중\n",
            "180 개 진행중\n",
            "190 개 진행중\n",
            "200 개 진행중\n",
            "210 개 진행중\n",
            "220 개 진행중\n",
            "230 개 진행중\n",
            "240 개 진행중\n",
            "250 개 진행중\n",
            "260 개 진행중\n",
            "270 개 진행중\n",
            "280 개 진행중\n",
            "290 개 진행중\n",
            "300 개 진행중\n",
            "310 개 진행중\n",
            "320 개 진행중\n",
            "330 개 진행중\n",
            "340 개 진행중\n",
            "350 개 진행중\n",
            "360 개 진행중\n",
            "370 개 진행중\n",
            "380 개 진행중\n",
            "390 개 진행중\n",
            "400 개 진행중\n",
            "410 개 진행중\n",
            "420 개 진행중\n",
            "430 개 진행중\n",
            "440 개 진행중\n",
            "450 개 진행중\n",
            "460 개 진행중\n",
            "470 개 진행중\n",
            "480 개 진행중\n",
            "490 개 진행중\n",
            "500 개 진행중\n",
            "510 개 진행중\n",
            "520 개 진행중\n",
            "530 개 진행중\n",
            "540 개 진행중\n",
            "550 개 진행중\n",
            "560 개 진행중\n",
            "570 개 진행중\n",
            "580 개 진행중\n",
            "590 개 진행중\n",
            "600 개 진행중\n",
            "610 개 진행중\n",
            "620 개 진행중\n",
            "630 개 진행중\n",
            "640 개 진행중\n",
            "650 개 진행중\n",
            "660 개 진행중\n",
            "670 개 진행중\n",
            "680 개 진행중\n",
            "690 개 진행중\n",
            "700 개 진행중\n",
            "710 개 진행중\n",
            "720 개 진행중\n",
            "730 개 진행중\n",
            "740 개 진행중\n",
            "750 개 진행중\n",
            "760 개 진행중\n",
            "770 개 진행중\n",
            "780 개 진행중\n",
            "790 개 진행중\n",
            "800 개 진행중\n",
            "810 개 진행중\n",
            "820 개 진행중\n",
            "830 개 진행중\n",
            "840 개 진행중\n",
            "850 개 진행중\n",
            "860 개 진행중\n",
            "870 개 진행중\n",
            "880 개 진행중\n",
            "890 개 진행중\n",
            "900 개 진행중\n",
            "910 개 진행중\n",
            "920 개 진행중\n",
            "930 개 진행중\n",
            "940 개 진행중\n",
            "950 개 진행중\n",
            "960 개 진행중\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summary_list"
      ],
      "metadata": {
        "id": "C_uIPVJOYtGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next_data['summary'] = summary_list"
      ],
      "metadata": {
        "id": "zhZ-ovz1Yuis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# >>>>>>>>>>>>>>>>>> 훈련 반복할 때마다 파일명 바꾸기 default -> 1 -> 2...\n",
        "next_data.to_csv('/content/drive/MyDrive/Colab Notebooks/graduation_project/kobart-kogpt_output/kobart_output_2.csv')"
      ],
      "metadata": {
        "id": "qDp8AuqbYxjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. 추가 train된 kobart에 tran set의 일기 데이터셋을 넣어 공감코멘트 생성 (.tsv)"
      ],
      "metadata": {
        "id": "4YsOTs9_aVxU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train 파일 재지정\n",
        "# kobart_output_n.csv 파일 정제 후 수행\n",
        "import pandas as pd\n",
        "\n",
        "# >>>>>>>>>>>>>>>>>> 훈련 반복할 때마다 파일명 바꾸기 default -> 1 -> 2...\n",
        "temp= pd.read_csv('/content/drive/MyDrive/Colab Notebooks/graduation_project/kobart-kogpt_output/kobart_output_2.csv', encoding='cp949')\n",
        "temp= temp[['news', 'summary']]\n",
        "temp.to_csv('/content/drive/MyDrive/Colab Notebooks/graduation_project/KoBART-summarization/data/train.tsv', sep='\\t')"
      ],
      "metadata": {
        "id": "qKnvV0M8ZoM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. (4)로 돌아가 (4) ~ (5) 과정을 반복 (생성되는 공감코멘트가 어느정도의 성능으로 수렴할 때까지)"
      ],
      "metadata": {
        "id": "iZ5WMY7YeKuo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "onOs7JdWagXh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}