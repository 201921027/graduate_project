{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOIMHo2yxVcHoW/THb+rBxT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/201921027/graduate_project_git/blob/main/_gp_bart_model_conv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOCarEVUJqw8",
        "outputId": "b8941a24-e5c7-4612-9348-7e6ee974557d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/MyDrive/Colab Notebooks/graduation_project'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LkxpM2iNvVO",
        "outputId": "d763ff4c-4aa3-48b0-f5e7-7a0fcb0ffa33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/graduation_project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "## CPU\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "## GPU\n",
        "# device = torch.device(\"cuda\")"
      ],
      "metadata": {
        "id": "CbjVmJARPdvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gluonnlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQ7PJ2ZxQV-N",
        "outputId": "6dea08e8-d0a5-4a7a-a5e2-5df67b94697a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gluonnlp in /usr/local/lib/python3.7/dist-packages (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (1.21.6)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (0.29.32)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp) (3.0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mxnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mewCrxuMQh-b",
        "outputId": "4089c141-bc2e-4eed-a82d-22d30df04b5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mxnet in /usr/local/lib/python3.7/dist-packages (1.7.0.post2)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.21.6)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from mxnet) (0.8.4)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3MP5S_9SZjz",
        "outputId": "f0b47fc7-4922-4449-c44f-1b20722050a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n",
            "  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-ui1nzz00\n",
            "  Running command git clone -q 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-ui1nzz00\n",
            "Requirement already satisfied: boto3<=1.15.18 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (1.15.18)\n",
            "Requirement already satisfied: gluonnlp<=0.10.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (0.10.0)\n",
            "Requirement already satisfied: mxnet<=1.7.0.post2,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (1.7.0.post2)\n",
            "Requirement already satisfied: onnxruntime<=1.8.0,==1.8.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (1.8.0)\n",
            "Requirement already satisfied: sentencepiece<=0.1.96,>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (0.1.96)\n",
            "Requirement already satisfied: torch<=1.10.1,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (1.10.1)\n",
            "Requirement already satisfied: transformers<=4.8.1,>=4.8.1 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (4.8.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (2.0.7)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (3.17.3)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (1.21.6)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from boto3<=1.15.18->kobert==0.2.3) (0.3.7)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3<=1.15.18->kobert==0.2.3) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.19.0,>=1.18.18 in /usr/local/lib/python3.7/dist-packages (from boto3<=1.15.18->kobert==0.2.3) (1.18.18)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.26,>=1.20 in /usr/local/lib/python3.7/dist-packages (from botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (1.24.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (21.3)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (0.29.32)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (0.8.4)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2.23.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2022.6.15)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<=1.10.1,>=1.7.0->kobert==0.2.3) (4.1.1)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (0.10.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (4.12.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (0.0.53)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (4.64.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (2022.6.2)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (0.0.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (3.8.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 사용자 input\n",
        "\n",
        "# 서버에서 본문 받아오기\n",
        "# 서버에서 아마 csv나 json으로 받아올텐데, 받아올 때 특수문자 처리 필수 (특히 따옴표 '', \"\")\n",
        "# '[제목] 본문' 형태로 전처리\n",
        "# //////////////////////서버로부터 본문 받아와서 str로 저장하는 line////////////////////////\n",
        "input_text= \"[아르바이트]한 달에 오 만원 정도의 용돈을 받아서 절반은 교통카드 충전을, \\\n",
        "또 절반은 친구들과 노는 곳에 주로 썼었다. 이 패턴은 고등학교를 다닐 때에도 마찬가지였다. \\\n",
        "한 달에 십 만원 정도의 용돈을 받아서 절반은 교통카드 충전 또 절반은 친구들과 노는 곳에 썼었지만 \\\n",
        "확실히 고등학교 때에는 돈이 모자르게만 느껴졌었고 아르바이트를 통해 부족한 돈을 충당하기보다는 \\\n",
        "버스를 타는 것 대신 삼십여분거리를 걸어서 등하교를 하고 그 교통비를 용돈에 보태서 쓰는 방법을 택했었다. \\\n",
        "어릴 때부터 용돈 받는선 일에 겁도 많이 났었지만 일단 한 번 해보자. 해봐야 뒷일도 아는 거니까라는 마음으로 \\\n",
        "첫 출근을 해서 일 년간 꾸준히 빵집 아르바이트를 통해 처음 저축도 하고 부모님께 선물도 사 드리고 \\\n",
        "내가 입고싶었던 옷, 핸드폰도 구입하고 보람찬 일들을 많이 했었기 때문에 \\\n",
        "아직도 그 빵집 앞을 지나갈 때나 혹은 익숙한 빵들을 보고 있을 때면 괜히 그때의 일들이 생각나 마음이 붕뜨고 설렌 적도 많았던 것 같다. \\\n",
        "부모님께 의존하고 부모님이 해주시는 모든 것들을 당연하게만 느꼈었던 과거의 나에게 지금의 내가 한마디 해줄 수 있다면 \\\n",
        "네가 받고 네가 누리고 있는 모든 것들에 항상 감사한 마음을 가지라고 해주고 싶다. \\\n",
        "별거 아니네라고 치부하며 낭비하지 말고 작은 것도 소중히 여겨 아낄 줄 아는 마음을 가진 내가 되었으면 좋겠다.\"\n"
      ],
      "metadata": {
        "id": "1VHcyE1YMgjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(input_text) + len(\" TL;DR \") > 800:\n",
        "  input_text = input_text[0:400] + input_text[len(input_text)-400:len(input_text)]"
      ],
      "metadata": {
        "id": "LAkARbuE48we"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* BERT"
      ],
      "metadata": {
        "id": "HPucZsPENgkO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from kobert import get_pytorch_kobert_model\n",
        "\n",
        "bertmodel, vocab  = get_pytorch_kobert_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPpGPRM1RfS8",
        "outputId": "bd093af1-3d56-4002-86e2-cd41feb99648"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cached model. /content/drive/MyDrive/Colab Notebooks/graduation_project/.cache/kobert_v1.zip\n",
            "using cached model. /content/drive/MyDrive/Colab Notebooks/graduation_project/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gluonnlp as nlp\n",
        "from kobert import get_tokenizer\n",
        "\n",
        "bert_tokenizer = get_tokenizer()\n",
        "tok = nlp.data.BERTSPTokenizer(bert_tokenizer, vocab, lower=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-FRbbeUTrt-",
        "outputId": "ebf0a3a5-e7d9-41db-bb9f-7b98d3c6850c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cached model. /content/drive/MyDrive/Colab Notebooks/graduation_project/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_size = 768,\n",
        "                 num_classes=5,\n",
        "                 dr_rate=None,\n",
        "                 params=None):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dr_rate = dr_rate\n",
        "                 \n",
        "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
        "        if dr_rate:\n",
        "            self.dropout = nn.Dropout(p=dr_rate)\n",
        "    \n",
        "    def gen_attention_mask(self, token_ids, valid_length):\n",
        "        attention_mask = torch.zeros_like(token_ids)\n",
        "        for i, v in enumerate(valid_length):\n",
        "            attention_mask[i][:v] = 1\n",
        "        return attention_mask.float()\n",
        "\n",
        "    def forward(self, token_ids, valid_length, segment_ids):\n",
        "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "        \n",
        "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
        "        if self.dr_rate:\n",
        "            out = self.dropout(pooler)\n",
        "        else:\n",
        "            out = pooler\n",
        "        return self.classifier(out)"
      ],
      "metadata": {
        "id": "62pl4s2NU2RI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)"
      ],
      "metadata": {
        "id": "7dwz_NOcU3JG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model load\n",
        "bert_model.load_state_dict(torch.load('./checkpoint/bert_model.pt', map_location=device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwKTN9fWMtaA",
        "outputId": "872aec38-a34e-4063-c5cf-7f526306fb57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 512"
      ],
      "metadata": {
        "id": "ce-8oXNVQIkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 기쁨:0 분노:1 혐오:2 두려움:3 슬픔:4 unknown:5\n",
        "\n",
        "def softmax(vals, idx):\n",
        "    valscpu = vals.cpu().detach().squeeze(0)\n",
        "    a = 0\n",
        "    for i in valscpu:\n",
        "        a += np.exp(i)\n",
        "    return ((np.exp(valscpu[idx]))/a).item() * 100\n",
        "\n",
        "def testModel(model, seq):\n",
        "    cate = [\"기쁨\", \"분노\", \"혐오\", \"두려움\", \"슬픔\", \"unknown\"]\n",
        "    tmp = [seq]\n",
        "    transform = nlp.data.BERTSentenceTransform(tok, max_len, pad=True, pair=False)\n",
        "    tokenized = transform(tmp)\n",
        "\n",
        "    model.eval()\n",
        "    result = model(torch.tensor([tokenized[0]]).to(device), [tokenized[1]], torch.tensor(tokenized[2]).to(device))\n",
        "    idx = result.argmax().cpu().item()\n",
        "    print(\"일기의 감정:\", cate[idx])\n",
        "    print(\"신뢰도:\", \"{:.2f}%\".format(softmax(result,idx)))\n",
        "    return cate[idx]"
      ],
      "metadata": {
        "id": "S_HkTCNbNqOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion= testModel(bert_model, input_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IueYeUeOWAFV",
        "outputId": "9b69981d-c51d-4770-ccfb-b07e114292f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "일기의 감정: 기쁨\n",
            "신뢰도: 90.09%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* KoBART"
      ],
      "metadata": {
        "id": "E-n-dezxWZCv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import PreTrainedTokenizerFast\n",
        "from transformers import BartForConditionalGeneration\n",
        "\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained('digit82/kobart-summarization')"
      ],
      "metadata": {
        "id": "SRvHV7-KXhN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BartForConditionalGeneration.from_pretrained('./KoBART-summarization/logs/model_chp')"
      ],
      "metadata": {
        "id": "01JRRDSu11Cr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(input_text) + len(\" TL;DR \") > 800:\n",
        "  input_text = input_text[0:400] + input_text[len(input_text)-400:len(input_text)]"
      ],
      "metadata": {
        "id": "b7xCdtFD272X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text= input_text + \" TL;DR \"\n",
        "text= emotion + '| ' + input_text\n",
        "\n",
        "text = text.replace('\\n', ' ')\n",
        "# print(text)"
      ],
      "metadata": {
        "id": "PWvB097YWCIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_input_ids = tokenizer.encode(text)\n",
        "input_ids = [tokenizer.bos_token_id] + raw_input_ids + [tokenizer.eos_token_id]\n",
        "\n",
        "summary_ids = model.generate(torch.tensor([input_ids]),  num_beams=4,  max_length=512,  eos_token_id=1)\n",
        "output= tokenizer.decode(summary_ids.squeeze().tolist(), skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "aKDaT9TMWNNw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88a42fe6-dce8-4675-c816-5b75edde4abd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1839: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  next_indices = next_tokens // vocab_size\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7_zp56n4ijI",
        "outputId": "a556c524-184e-44ec-ce08-0c2a82526cbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "아르바이트를 통해 부족한 돈을 충당하기보다는 버스를 타는 것 대신 삼십여분거리를 걸어서 등하교를 하고 그 교통비를 용돈에 보태서 쓰는 방법을 택했군요. 분명 좋은 결과가 있을 거에요!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gQLRh7uUYcPK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}